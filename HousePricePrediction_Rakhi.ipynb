{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rakhi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.0)\n",
      "Collecting scikit-learn>=0.21 (from imbalanced-learn->imblearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/9e/6a42486ffa64711fb868e5d4a9167153417e7414c3d8d3e0d627cf391e1e/scikit_learn-0.21.3-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\rakhi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\rakhi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.5.0 imblearn-0.0 scikit-learn-0.21.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008abc\"><b>House price prediction:</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#008abc\"><b>Problem Statement</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file below.\n",
    "\n",
    "The company is looking at prospective properties to buy to enter the market.Build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n",
    "\n",
    "The company wants to know:\n",
    "\n",
    "- Which variables are significant in predicting the price of a house, and\n",
    "\n",
    "- How well those variables describe the price of a house.\n",
    "\n",
    "Also, determine the optimal value of lambda for ridge and lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#008abc\"><b>Business Goal</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables.\n",
    "- They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. \n",
    "- Further, the model will be a good way for the management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008abc\"><b> Data Preparation</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d2d5214b4661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m params = {'legend.fontsize': 'x-large',\n\u001b[0;32m     11\u001b[0m           \u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'vq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hierarchy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_testutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_hierarchy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_optimal_leaf_ordering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "# Analysis and computation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (10,8),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.labelcolor': '#008abc',\n",
    "         'axes.titlesize':'15',\n",
    "         'text.color':'green',\n",
    "         'axes.titlepad': 35,\n",
    "         'xtick.labelsize':'small',\n",
    "         'ytick.labelsize':'small'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Model building & evaluation\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm \n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Autocomplete in cell\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#008abc\">Read the data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#008abc\">Inspect the data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['Id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> No duplicate values found</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> We find few columns with missing values. Let's further check on the percenatge of values that are missing.\n",
    "</div>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#008abc'>Data Cleaning</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Percentage of NULL values\n",
    "mis_val_percent = round((100 * housing_df.isnull().sum() / len(housing_df)),2)\n",
    "\n",
    "## Fetch columns where percentage of missing records is greater than 0\n",
    "mis_cols=mis_val_percent.loc[(mis_val_percent>0)].sort_values(ascending=False)\n",
    "mis_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        There are few columns that do not even contain close to 50% of the data. We will remove those columns as imputing them with values might introduce bias in the dataset.\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Droppig columns with grater tha 45% data is missing\n",
    "housing_df.drop(mis_cols[mis_cols>45].index,inplace=True,axis=1)\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns dropped\n",
    "mis_cols[mis_cols>45].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop('MiscVal',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        As we have dropped the <b>MiscFeature</b>, we can also drop the <b>MiscVal</b> ,as it is nothing but the value of the corresponding feature. Let's handle cases where the missing values are less than 20%.\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <span style=\"color:#008abc\">Handle missing values </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch column containing less than 45% of missing values\n",
    "mis_cols[mis_cols<45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's analyze the above columns based on their datatypes and relations, to check if the column/rows needs to be retained and decide on the imputation to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <font color='#008abc'>Categorical variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch string datatypes\n",
    "categorical_col = list(housing_df[mis_cols[mis_cols<45].index].select_dtypes(include='object').columns)\n",
    "\n",
    "## Identify the top values and it's frequency\n",
    "housing_df[categorical_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to plot the data and print the top value % contribution\n",
    "def check_col(col):\n",
    "    from IPython.display import display, HTML\n",
    "    sns.countplot(housing_df[col])\n",
    "    plt.title(col +\": Percentage of missing value:\"+str(mis_cols[col])+\"%\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()\n",
    "    text='''The top value is <b>%s</b> and it makes up for <b>%s</b> amount of the data'''%(housing_df[col].value_counts().idxmax(),round((housing_df[col].value_counts().max()/housing_df[col].count()*100),2))\n",
    "    data=HTML('''<div class=\"alert alert-block alert-info\"><span style=\"color:black\">'''+text+'''</span></div>''')\n",
    "    display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns related to Garage\n",
    "Garage_missing = mis_cols[categorical_col[0:4]].index\n",
    "Garage_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[Garage_missing]=housing_df[Garage_missing].replace(np.nan,'No Garage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <b>NA</b> values in the 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond' columns mean <b>No Garage</b> as per the metadata description. So we have replaced the same for the missing values.\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns related to Basement\n",
    "Bsmt_missing = mis_cols[categorical_col[4:9]].index\n",
    "Bsmt_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[Bsmt_missing]=housing_df[Bsmt_missing].replace(np.nan,'No Basement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <b>NA</b> values in the 'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual' columns mean <b>No Basement</b> as per the metadata description. So we have replaced the same for the missing values.\n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Masonry veneer type column - categorical_col[9]\n",
    "check_col(categorical_col[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[housing_df[categorical_col[9]].isnull()]['MasVnrArea'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "      As the MasVnrArea is also null, we can assume that there was no veneer type, hence we will replace the missing values with None  \n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[categorical_col[9]]=housing_df[categorical_col[9]].replace(np.nan,'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Electrical - categorical_col[10]\n",
    "check_col(categorical_col[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As the evident top contributor, we will replace the missing values with SBrkr\n",
    "housing_df[categorical_col[10]]=housing_df[categorical_col[10]].replace(np.nan,'SBrkr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <font color='#008abc'>Numerical variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch numerical datatypes\n",
    "int_mis_cols=housing_df[mis_cols[mis_cols<45].index].select_dtypes(include='float').columns\n",
    "int_mis_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LotFrontage\n",
    "print(\"LotFrontage contains %s missing values\"%(mis_cols.LotFrontage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['LotFrontage']=housing_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "     As most of the lots in a similar neighbhourhood contain similar feet of street connected to the Lot, we have imputed the missing values by using the median values for a neighbhourhood.   \n",
    "    </span>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The integer variables ar ehandled in a similar fashion like the categorical counterparts\n",
    "housing_df[int_mis_cols[1]]=housing_df[int_mis_cols[1]].replace(np.nan,0)\n",
    "housing_df[int_mis_cols[2]]=housing_df[int_mis_cols[2]].replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Percentage of NULL values\n",
    "mis_val_percent = round((100 * housing_df.isnull().sum() / len(housing_df)),2)\n",
    "mis_val_percent[mis_val_percent>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> We find that all the missing values are handled. Now let's perform EDA on the dataset.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008abc\">Analyze the dataset :EDA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.columns.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Area columns with respect to SalePrice\n",
    "plt.figure(figsize=(16,13))\n",
    "plt.subplot(2,3,1)\n",
    "plt.scatter(housing_df['MasVnrArea'],housing_df.SalePrice)\n",
    "plt.title('MasVnrArea vs SalePrice')\n",
    "plt.subplot(2,3,2)\n",
    "plt.scatter(housing_df['TotalBsmtSF'],housing_df.SalePrice)\n",
    "plt.title('TotalBsmtSF vs SalePrice')\n",
    "plt.subplot(2,3,3)\n",
    "plt.scatter(housing_df['1stFlrSF'],housing_df.SalePrice)\n",
    "plt.title('1stFlrSF vs SalePrice')\n",
    "plt.subplot(2,3,4)\n",
    "plt.scatter(housing_df['GarageArea'],housing_df.SalePrice)\n",
    "plt.title('GarageArea vs SalePrice')\n",
    "plt.subplot(2,3,5)\n",
    "plt.scatter(housing_df['GrLivArea'],housing_df.SalePrice)\n",
    "plt.title('GrLivArea vs SalePrice')\n",
    "plt.subplot(2,3,6)\n",
    "plt.scatter(housing_df['LotArea'],housing_df.SalePrice)\n",
    "plt.title('LotArea vs SalePrice')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <ul>\n",
    "            <li> We find that the outliers are affecting the salesprice, but most of the ares have a linear relationship with price.</li>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### <span style=\"color:#008abc\">Analyze the target variable</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b>From the plot we can see that the <b>Sale Price</b>is skewed towards the left.Let's handle the skewness using the log transformation. </span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.SalePrice=np.log(housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008abc\">Data Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Year as number of years from current year\n",
    "import datetime\n",
    "curr_year=datetime.datetime.now().year\n",
    "housing_df['YearBuilt'] = curr_year - housing_df['YearBuilt']\n",
    "housing_df['YearRemodAdd'] = curr_year - housing_df['YearRemodAdd']\n",
    "housing_df['GarageYrBlt'] = curr_year - housing_df['GarageYrBlt']\n",
    "housing_df['YrSold'] = curr_year - housing_df['YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the integer variables which are categorical in nature.\n",
    "Numerics=['int64','float64']\n",
    "integer_cols=housing_df.select_dtypes(include=Numerics)\n",
    "integer_cols.drop('Id',axis=1,inplace=True)\n",
    "int_cols = integer_cols.nunique()\n",
    "int_cols[int_cols<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert integer levels to categorical type\n",
    "housing_df['MSSubClass'] = housing_df['MSSubClass'].astype('object')\n",
    "housing_df['OverallQual'] = housing_df['OverallQual'].astype('object')\n",
    "housing_df['OverallCond'] = housing_df['OverallCond'].astype('object')\n",
    "housing_df['BsmtFullBath'] = housing_df['BsmtFullBath'].astype('object')\n",
    "housing_df['BsmtHalfBath'] = housing_df['BsmtHalfBath'].astype('object')\n",
    "housing_df['FullBath'] = housing_df['FullBath'].astype('object')\n",
    "housing_df['HalfBath'] = housing_df['HalfBath'].astype('object')\n",
    "housing_df['BedroomAbvGr'] = housing_df['BedroomAbvGr'].astype('object')\n",
    "housing_df['KitchenAbvGr'] = housing_df['KitchenAbvGr'].astype('object')\n",
    "housing_df['TotRmsAbvGrd'] = housing_df['TotRmsAbvGrd'].astype('object')\n",
    "housing_df['Fireplaces'] = housing_df['Fireplaces'].astype('object')\n",
    "housing_df['GarageCars'] = housing_df['GarageCars'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the correlation among the numerics features\n",
    "Numerics=['int64','float64']\n",
    "integer_cols=housing_df.select_dtypes(include=Numerics)\n",
    "int_corr=integer_cols.corr()\n",
    "int_corr=int_corr.transform(lambda x : round(x,2))\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(int_corr,cmap = plt.cm.RdYlBu_r, annot=True,vmin = -0.00,vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <font color='#008abc'> Outlier Handling</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop outliers for numerical columns using the Interquartile range\n",
    "num_col = housing_df.select_dtypes(include=Numerics).columns\n",
    "num_col.drop('Id')\n",
    "# num_col = ['LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','1stFlrSF','GrLivArea','OpenPorchSF',\n",
    "#            'EnclosedPorch','3SsnPorch',\n",
    "#            'ScreenPorch' ,'PoolArea','MiscVal','SalePrice']\n",
    "def drop_outliers(x):\n",
    "    \n",
    "    for col in num_col:\n",
    "        Q1 = x[col].quantile(.05)\n",
    "        Q3 = x[col].quantile(.95)\n",
    "        IQR = Q3-Q1\n",
    "        x =  x[(x[col] >= (Q1-(1.5*IQR))) & (x[col] <= (Q3+(1.5*IQR)))] \n",
    "    return x   \n",
    "\n",
    "housing_df = drop_outliers(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[num_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Area columns with respect to SalePrice\n",
    "plt.figure(figsize=(16,13))\n",
    "plt.subplot(2,3,1)\n",
    "plt.scatter(housing_df['MasVnrArea'],housing_df.SalePrice)\n",
    "plt.title('MasVnrArea vs SalePrice')\n",
    "plt.subplot(2,3,2)\n",
    "plt.scatter(housing_df['TotalBsmtSF'],housing_df.SalePrice)\n",
    "plt.title('TotalBsmtSF vs SalePrice')\n",
    "plt.subplot(2,3,3)\n",
    "plt.scatter(housing_df['1stFlrSF'],housing_df.SalePrice)\n",
    "plt.title('1stFlrSF vs SalePrice')\n",
    "plt.subplot(2,3,4)\n",
    "plt.scatter(housing_df['GarageArea'],housing_df.SalePrice)\n",
    "plt.title('GarageArea vs SalePrice')\n",
    "plt.subplot(2,3,5)\n",
    "plt.scatter(housing_df['GrLivArea'],housing_df.SalePrice)\n",
    "plt.title('GrLivArea vs SalePrice')\n",
    "plt.subplot(2,3,6)\n",
    "plt.scatter(housing_df['LotArea'],housing_df.SalePrice)\n",
    "plt.title('LotArea vs SalePrice')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <ul>\n",
    "            <li> We find that after removing the outliers the inear relationship with price is more clear.</li>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <font color='#008abc'>Create Dummy variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat=housing_df.nunique()\n",
    "binary_cols=col_cat[col_cat<3]\n",
    "binary_cols.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[binary_cols.index].apply(lambda x :print(x.name,x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop(['LowQualFinSF','3SsnPorch','PoolArea'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['Street']=housing_df['Street'].map({'Pave': 1, 'Grvl': 0})\n",
    "housing_df['Utilities']=housing_df['Utilities'].map({'AllPub': 1, 'NoSeWa': 0})\n",
    "housing_df['CentralAir']=housing_df['CentralAir'].map({'Y': 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding\n",
    "categorical_fields=housing_df.select_dtypes(include='object')\n",
    "categorical_columns=categorical_fields.nunique().sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_vars = pd.get_dummies(housing_df[categorical_columns], drop_first=True)\n",
    "dummy_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.concat([housing_df, dummy_vars], axis=1)\n",
    "housing_df = housing_df.drop(categorical_columns, axis = 1)\n",
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_df = housing_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_df.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_df.select_dtypes(include=Numerics).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#008abc'>Splitting Data into Training and Testing Sets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(house_price_df, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rescaling the features\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_train_scaled = scaler.fit_transform(df_train.values)\n",
    "df_train = pd.DataFrame(df_train_scaled, index=df_train.index, columns=df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#008abc'>Model Building</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into X and Y set for model building\n",
    "\n",
    "y_train = df_train.pop('SalePrice')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#008abc'>Ridge Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the best parameter lambda and the best NMSE score\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=1000]\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <ul>\n",
    "            <li>From the above graph and best parameter we have alpha as <b>4</b></li>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train, y_train)\n",
    "r_coeff=ridge.coef_\n",
    "r_coeff[r_coeff!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the R-squared value of test and train data\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "RR2=metrics.r2_score(y_train, y_train_pred)\n",
    "print(\"Ridge R squared (train):\",RR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#008abc'>Lasso Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Mean Absolute Error')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.title(\"Negative Mean Absolute Error and alpha\")\n",
    "plt.legend(['train score', 'test score'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b> \n",
    "        <ul>\n",
    "            <li>From the above graph and best parameter we have alpha as <b>0.0001</b></li>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "lasso = Lasso(alpha=alpha)      \n",
    "lasso.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_c=lasso.coef_\n",
    "lasso_c[lasso_c!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the R-squared value of test and train data\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "LR2=metrics.r2_score(y_true=y_train, y_pred=y_train_pred)\n",
    "print(\"Lasso R squared(Train)\",LR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#008abc'>Model Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled = scaler.transform(df_test.values)\n",
    "df_test = pd.DataFrame(df_test_scaled, index=df_test.index, columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into X and Y set for model building\n",
    "\n",
    "y_test = df_test.pop('SalePrice')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the R-squared value of test and train data\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "LR2TS=metrics.r2_score(y_true=y_test, y_pred=y_test_pred)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "LRMSE= mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets predict the R-squared value of test and train data\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "RR2TS=metrics.r2_score(y_true=y_test, y_pred=y_test_pred)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RRMSE=mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#008abc'>Metrics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge\")\n",
    "print(\"Train R square\",RR2)\n",
    "print(\"Test R square\",RR2TS)\n",
    "print(\"RMSE\",RRMSE)\n",
    "\n",
    "print(\"Lasso\")\n",
    "print(\"Train R square\",LR2)\n",
    "print(\"Test R square\",LR2TS)\n",
    "print(\"RMSE\",LRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = list(ridge.coef_)\n",
    "cols = list(df_train.columns)\n",
    "ridge_coef = pd.DataFrame(list(zip(cols,model_param)))\n",
    "ridge_coef.columns = ['Featuere','Coef']\n",
    "ridge_coef.sort_values(by='Coef',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = list(lasso.coef_)\n",
    "cols = list(df_train.columns)\n",
    "lasso_coef = pd.DataFrame(list(zip(cols,model_param)))\n",
    "lasso_coef.columns = ['Featuere','Coef']\n",
    "lasso_coef.sort_values(by='Coef',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef.sort_values(by='Coef',ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Inference:</b>\n",
    "        From the scores we can find that the R2 scores and RMSE are quite similar for both the models. We can go with Lasso regression,\n",
    "        as the number of features are reduced due to feature elimination and even with small value of alpha many of the coefficients are reducing to absolute zeroes\n",
    "        </span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Suggestions:</b> Factors that positively affect the price of the house are\n",
    "         <ul>\n",
    "            <li><b>GrLivArea:</b> Above grade (ground) living area square feet</li>\n",
    "            <li><b>TotalBsmtSF:</b> Total square feet of basement area</li>\n",
    "            <li><b>OverallQual:</b> Rates the overall material and finish of the house. The higher the quality, the higher is the impact on the price.\n",
    "                <b>10</b> - Very Excellent\n",
    "                <b> 9</b> - Excellent\n",
    "                <b> 8</b> - Very Good\n",
    "            </li>\n",
    "            <li><b>BsmtFinSF1:</b> Type 1 finished square feet</li>\n",
    "            <li><b>GarageArea:</b> Size of garage in square feet</li>\n",
    "            <li><b>Neighborhood:</b> Physical locations within Ames city limits. The prices are high in </li>\n",
    "                <b>Stone Brook</b>\n",
    "                <b>Crawford</b>\n",
    "            <li><b>LotArea:</b> Lot size in square feet</li>\n",
    "            </ul>\n",
    "        </span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style=\"color:black\"><b>Suggestions:</b> Factors that negatively affect the price of the house are, these values lead to lower price\n",
    "         <ul>\n",
    "            <li><b>YearBuilt:</b> Above grade (ground) living area square feet</li>\n",
    "            <li><b>Gravity furnace</b> \n",
    "            <li><b>OverallQual:</b> Rates the overall material and finish of the house. The lower the quality, the lesser is the price.\n",
    "            </li>\n",
    "            <li><b>Average/Typical or FairKitchen Quality</b></li>\n",
    "            <li><b>Fair Exterior Quality</b> </li>\n",
    "            </ul>\n",
    "        </span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
